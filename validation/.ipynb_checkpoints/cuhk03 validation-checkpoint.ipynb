{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CUHK03MAT = '/path/to/cuhk-03.mat'\n",
    "CUHK03_MODELS_ROOT = '../models/cuhk03/'\n",
    "CAFFE_ROOT = '../caffe-master/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import cv2\n",
    "import random as rnd\n",
    "import os\n",
    "from os import walk\n",
    "caffe_root = CAFFE_ROOT  # this file is expected to be in {caffe_root}/examples/siameseimport sys\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import caffe\n",
    "import numpy as np\n",
    "sys.path.insert(0, '/')\n",
    "import data_preprocessing as dp\n",
    "import ranking as rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ensure_dir(f):\n",
    "    d = os.path.dirname(f)\n",
    "    if not os.path.exists(d):\n",
    "        os.makedirs(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_name(prefix, camera_num, person_id, photo_num):\n",
    "    return prefix+\"_\"+str(camera_num)+\"_\"+str(person_id)+\"_\"+str(photo_num)+\".png\"\n",
    "\n",
    "def parseCuhk03(dataset_path, writeImages = False, root = ''):\n",
    "    dataset = h5py.File(dataset_path)\n",
    "    labeled = dataset['labeled']\n",
    "    detected = dataset['detected']\n",
    "    \n",
    "    labeled_dict = dict()\n",
    "    detected_dict = dict()\n",
    "    \n",
    "    labeled_dict['cam_a'] = dict()\n",
    "    labeled_dict['cam_b'] = dict()\n",
    "    \n",
    "    detected_dict['cam_a'] = dict()\n",
    "    detected_dict['cam_b'] = dict()\n",
    "    \n",
    "    for cam_pair_num in xrange(labeled.shape[1]) : #cam\n",
    "        cam_pair_labeled = dataset[labeled[0][cam_pair_num]]\n",
    "        for i in xrange(cam_pair_labeled.shape[1]): #ids\n",
    "            for j in xrange(cam_pair_labeled.shape[0]): #photos [1..10]\n",
    "                curr_im_labeled = dataset[cam_pair_labeled[j][i]][:];\n",
    "                if curr_im_labeled.shape == (2,) :\n",
    "                    continue;\n",
    "                    \n",
    "                person_id = (cam_pair_num + 1) * 1000 + i + 1;\n",
    "                im = cv2.cvtColor(curr_im_labeled.transpose((2,1,0)), cv2.COLOR_RGB2BGR)\n",
    "                if writeImages:\n",
    "                    dirname = os.path.join(root , \"labeled\",str(cam_pair_num+1)) + \"/\"\n",
    "                    ensure_dir(dirname)\n",
    "                    imname = os.path.join(root ,\"labeled\",str(cam_pair_num+1), image_name(\"labeled\", cam_pair_num+1, \n",
    "                                                                                          person_id, j) )\n",
    "                    cv2.imwrite(imname, im)\n",
    "\n",
    "                if j <= 4 :\n",
    "                    if person_id not in  labeled_dict['cam_a'] :\n",
    "                        labeled_dict['cam_a'][person_id] = list()\n",
    "                    labeled_dict['cam_a'][person_id].append(im)\n",
    "                else :\n",
    "                    if person_id not in  labeled_dict['cam_b'] :\n",
    "                        labeled_dict['cam_b'][person_id] = list()\n",
    "                    labeled_dict['cam_b'][person_id].append(im)\n",
    "                    \n",
    "    for cam_pair_num in xrange(detected.shape[1]) :\n",
    "        cam_pair_detected = dataset[detected[0][cam_pair_num]]\n",
    "        \n",
    "        for i in xrange(cam_pair_detected.shape[1]): #ids\n",
    "            for j in xrange(cam_pair_detected.shape[0]): #photos [1..10]\n",
    "                curr_im_detected = dataset[cam_pair_detected[j][i]][:];\n",
    "                if curr_im_detected.shape == (2,) :\n",
    "                    continue;\n",
    "\n",
    "                person_id = (cam_pair_num + 1) * 1000 + i + 1;\n",
    "                im = cv2.cvtColor(curr_im_detected.transpose((2,1,0)), cv2.COLOR_RGB2BGR)\n",
    "                if writeImages:\n",
    "                    dirname = os.path.join(root ,\"detected\",str(cam_pair_num+1)) + \"/\"\n",
    "                    ensure_dir(dirname)\n",
    "                    cv2.imwrite(os.path.join(root ,\"detected\",str(cam_pair_num+1), image_name(\"detected\", cam_pair_num+1,\n",
    "                                                                                              person_id,j) ), im)\n",
    "                if j <= 4 :\n",
    "                    if person_id not in  detected_dict['cam_a'] :\n",
    "                        detected_dict['cam_a'][person_id] = list()\n",
    "                    detected_dict['cam_a'][person_id].append(im)\n",
    "                else :\n",
    "                    if person_id not in  detected_dict['cam_b'] :\n",
    "                        detected_dict['cam_b'][person_id] = list()\n",
    "                    detected_dict['cam_b'][person_id].append(im)\n",
    "                    \n",
    "    return  labeled_dict, detected_dict      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getDescriptorsFromDatasetDict(net, dataset_dict, test_labels, feat_name = 'ip1_reid', batch = 128):\n",
    "    \n",
    "    descriptors = dict()\n",
    "    count = 0\n",
    "    ims = []\n",
    "    labels = []\n",
    "    net.blobs['data'].reshape(batch, 9, 60, 60)\n",
    "    for label in test_labels:\n",
    "        for arr in dataset_dict[label]:\n",
    "            \n",
    "            if count == batch:\n",
    "                count = 0\n",
    "                res = net.forward_all(data=np.array(ims))[feat_name]\n",
    "                for i in range(np.shape(res)[0]):\n",
    "                    descriptors[labels[i]].append(res[i].astype('float64'))\n",
    "\n",
    "                del ims[:]\n",
    "                del labels[:]\n",
    "\n",
    "            if (not label in descriptors):\n",
    "                descriptors[label] = []\n",
    "            ima = np.copy(arr)/256.\n",
    "            ims.append(ima)\n",
    "            labels.append(label)\n",
    "            count +=1;             \n",
    "\n",
    "    res = net.forward_all(data=np.array(ims))[feat_name]\n",
    "    for i in range(np.shape(res)[0]):\n",
    "        descriptors[labels[i]].append(res[i].astype('float64'));    \n",
    "                  \n",
    "    return descriptors;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cuhk03 dataset contains evaluation protocols\n",
    "#gets train- test split with particular num, train and validation should be broken later \n",
    "#numeration from 1\n",
    "#train and test are FROM 1-3 pairs of cameras in CUHK03\n",
    "def getTestSet(dataset_path, num) :\n",
    "    dataset = h5py.File(dataset_path)\n",
    "    #for i in xrange(dataset['testsets'].shape[1]):\n",
    "    print dataset[dataset['testsets'][0][num-1]].shape\n",
    "    test_set = set()\n",
    "    for j in xrange(dataset[dataset['testsets'][0][num-1]].shape[1]) :\n",
    "        person_id = np.int(dataset[dataset['testsets'][0][num-1]][0][j] * 1000 + dataset[dataset['testsets'][0][num-1]][1][j])\n",
    "        test_set.add(person_id)\n",
    "        \n",
    "    return test_set\n",
    "\n",
    "\n",
    "\n",
    "def similarity(x, y):\n",
    "    xy = np.dot(x,y);\n",
    "    xx = np.dot(x,x)\n",
    "    yy = np.dot(y,y)\n",
    "    return xy*1.0/np.sqrt(xx*yy)\n",
    "\n",
    "\n",
    "def get_random_elements(person_descr_dict):\n",
    "    result = dict()\n",
    "    for p in person_descr_dict:\n",
    "        result[p] = rnd.sample(person_descr_dict[p], 1)[0]\n",
    "    return result    \n",
    "\n",
    "\n",
    "\n",
    "def averageRankingSingleShot(descr_probe, descr_gallery, maxrank = 50, iterations =100):\n",
    "    ranks = np.zeros(maxrank)\n",
    "    for i in xrange(iterations):\n",
    "        descr_probe_i = get_random_elements(descr_probe)\n",
    "        descr_gallery_i = get_random_elements(descr_gallery)\n",
    "        \n",
    "        \n",
    "        descrs_query = []\n",
    "        query_labels = []\n",
    "\n",
    "        for p in descr_probe_i.keys():\n",
    "            query_labels.append(p)\n",
    "            descrs_query.append(descr_probe_i[p])\n",
    "\n",
    "    \n",
    "        descrs_gallery = []\n",
    "        gallery_labels = []\n",
    "\n",
    "        for p in descr_gallery_i.keys():\n",
    "            gallery_labels.append(p)\n",
    "            descrs_gallery.append(descr_gallery_i[p])\n",
    "    \n",
    "        \n",
    "        r = rank.ranking(descrs_query,query_labels,  descrs_gallery, gallery_labels, maxrank = maxrank)\n",
    "        ranks+=r\n",
    "        \n",
    "    return ranks*1./iterations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Recall@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled, detected = parseCuhk03(CUHK03MAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100)\n",
      "(2, 100)\n",
      "(2, 100)\n",
      "(2, 100)\n",
      "(2, 100)\n"
     ]
    }
   ],
   "source": [
    "#get standard test splits\n",
    "split1_test = getTestSet(CUHK03MAT, 1)\n",
    "split2_test = getTestSet(CUHK03MAT, 2)\n",
    "split3_test = getTestSet(CUHK03MAT, 3)\n",
    "split4_test = getTestSet(CUHK03MAT, 4)\n",
    "split5_test = getTestSet(CUHK03MAT, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "transform_params = dict()\n",
    "transform_params['reshape_params'] = dict()\n",
    "transform_params['reshape_params']['stripes'] = 3\n",
    "transform_params['reshape_params']['overlap'] = 10\n",
    "transform_params['reshape_params']['resize'] = (60, 160)\n",
    "cuhk03_dict_prepared_cam_a = dp.prepareDataset(labeled['cam_a'], transform_params)\n",
    "cuhk03_dict_prepared_cam_b = dp.prepareDataset(labeled['cam_b'], transform_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MODEL_FILE = os.path.join(CUHK03_MODELS_ROOT, 'train_val_model.prototxt')\n",
    "WEIGHTS =  os.path.join(CUHK03_MODELS_ROOT, 'split1_bs256.caffemodel')\n",
    "caffe.set_mode_gpu()\n",
    "net = caffe.Classifier(MODEL_FILE,WEIGHTS)\n",
    "cam_a_descr_split1 = getDescriptorsFromDatasetDict(net, cuhk03_dict_prepared_cam_a, \n",
    "                                                   test_labels = split1_test, feat_name = 'ip1_reid')\n",
    "cam_b_descr_split1 = getDescriptorsFromDatasetDict(net, cuhk03_dict_prepared_cam_b, \n",
    "                                                   test_labels = split1_test,feat_name = 'ip1_reid')\n",
    "labeled_split1_singleshot = averageRankingSingleShot(cam_a_descr_split1, cam_b_descr_split1, \n",
    "                                                     maxrank = 50, iterations =100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_FILE = os.path.join(CUHK03_MODELS_ROOT, 'train_val_model.prototxt')\n",
    "WEIGHTS =  os.path.join(CUHK03_MODELS_ROOT, 'split2_bs256.caffemodel')\n",
    "caffe.set_mode_gpu()\n",
    "net = caffe.Classifier(MODEL_FILE,WEIGHTS)\n",
    "cam_a_descr_split2 = getDescriptorsFromDatasetDict(net, cuhk03_dict_prepared_cam_a, \n",
    "                                                   test_labels = split2_test, feat_name = 'ip1_reid')\n",
    "cam_b_descr_split2 = getDescriptorsFromDatasetDict(net, cuhk03_dict_prepared_cam_b, \n",
    "                                                   test_labels = split2_test,feat_name = 'ip1_reid')\n",
    "labeled_split2_singleshot = averageRankingSingleShot(cam_a_descr_split2, cam_b_descr_split2, \n",
    "                                                     maxrank = 50, iterations =100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_FILE = os.path.join(CUHK03_MODELS_ROOT, 'train_val_model.prototxt')\n",
    "WEIGHTS =  os.path.join(CUHK03_MODELS_ROOT, 'split3_bs256.caffemodel')\n",
    "caffe.set_mode_gpu()\n",
    "net = caffe.Classifier(MODEL_FILE,WEIGHTS)\n",
    "cam_a_descr_split3 = getDescriptorsFromDatasetDict(net, cuhk03_dict_prepared_cam_a, \n",
    "                                                   test_labels = split3_test, feat_name = 'ip1_reid')\n",
    "cam_b_descr_split3 = getDescriptorsFromDatasetDict(net, cuhk03_dict_prepared_cam_b, \n",
    "                                                   test_labels = split3_test,feat_name = 'ip1_reid')\n",
    "labeled_split3_singleshot = averageRankingSingleShot(cam_a_descr_split3, cam_b_descr_split3, \n",
    "                                                     maxrank = 50, iterations =100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_FILE = os.path.join(CUHK03_MODELS_ROOT, 'train_val_model.prototxt')\n",
    "WEIGHTS =  os.path.join(CUHK03_MODELS_ROOT, 'split4_bs256.caffemodel')\n",
    "caffe.set_mode_gpu()\n",
    "net = caffe.Classifier(MODEL_FILE,WEIGHTS)\n",
    "cam_a_descr_split4 = getDescriptorsFromDatasetDict(net, cuhk03_dict_prepared_cam_a, test_labels = split4_test, feat_name = 'ip1_reid')\n",
    "cam_b_descr_split4 = getDescriptorsFromDatasetDict(net, cuhk03_dict_prepared_cam_b, test_labels = split4_test,feat_name = 'ip1_reid')\n",
    "labeled_split4_singleshot = averageRankingSingleShot(cam_a_descr_split4, cam_b_descr_split4, \n",
    "                                                     maxrank = 50, iterations =100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_FILE = os.path.join(CUHK03_MODELS_ROOT, 'train_val_model.prototxt')\n",
    "WEIGHTS =  os.path.join(CUHK03_MODELS_ROOT, 'split5_bs256.caffemodel')\n",
    "caffe.set_mode_gpu()\n",
    "net = caffe.Classifier(MODEL_FILE,WEIGHTS)\n",
    "cam_a_descr_split5 = getDescriptorsFromDatasetDict(net, cuhk03_dict_prepared_cam_a, \n",
    "                                                   test_labels = split5_test, feat_name = 'ip1_reid')\n",
    "cam_b_descr_split5 = getDescriptorsFromDatasetDict(net, cuhk03_dict_prepared_cam_b, \n",
    "                                                   test_labels = split5_test,feat_name = 'ip1_reid')\n",
    "labeled_split5_singleshot = averageRankingSingleShot(cam_a_descr_split5, cam_b_descr_split5, \n",
    "                                                     maxrank = 50, iterations =100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled_singleshot = (labeled_split1_singleshot+ \\\n",
    "                      labeled_split2_singleshot+ \\\n",
    "                      labeled_split3_singleshot+ \\\n",
    "                      labeled_split4_singleshot+ \\\n",
    "                      labeled_split5_singleshot)/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65918 0.92856 0.97594 0.9946 0.99798\n"
     ]
    }
   ],
   "source": [
    "print labeled_singleshot[0], labeled_singleshot[4], labeled_singleshot[9], labeled_singleshot[19], labeled_singleshot[29]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
